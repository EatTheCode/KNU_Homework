{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab_11_joohyung.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "rMtZRCurQBNT",
        "outputId": "b39a8aed-3198-4d61-eff3-a90aa031b93f"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from scipy import ndimage\n",
        "\n",
        "# eager 활성화\n",
        "# 텐서플로의 즉시 실행은 그래프를 생성하지 않고 함수를 바로 실행하는 명령형 프로그래밍 환경\n",
        "# 텐서플로 2.0은 기본으로 활성화 되어있는 옵션\n",
        "# tf.enable_eager_execution()\n",
        "\n",
        "# 1) hyper parameter 세팅\n",
        "\n",
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100\n",
        "\n",
        "\n",
        "# checkpoint를 저장할 디렉토리 설정\n",
        "# Option\n",
        "\n",
        "cur_dir = os.getcwd()\n",
        "ckpt_dir_name = 'checkpoints'\n",
        "model_dir_name = 'minst_cnn_seq'\n",
        "\n",
        "checkpoint_dir = os.path.join(cur_dir, ckpt_dir_name, model_dir_name)\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, model_dir_name)\n",
        "\n",
        "# Data augmentation\n",
        "def data_augmentation(images, labels):\n",
        "    # 이미지와 레이블을 저장할 리스트 생성\n",
        "    aug_images = []\n",
        "    aug_labels = []\n",
        "\n",
        "    # 오리지널 이미지와 레이블 저장\n",
        "    for x, y in zip(images, labels):\n",
        "        aug_images.append(x)\n",
        "        aug_labels.append(y)\n",
        "\n",
        "        # 중간 데이터 저장 - rotate나 shift를 하면서 비는 부분을 채우는 용도\n",
        "        bg_value = np.median(x)\n",
        "        for _ in range(4):\n",
        "            # 회전\n",
        "            angle = np.random.randint(-15, 15, 1)\n",
        "            rot_img = ndimage.rotate(x, angle, reshape=False, cval=bg_value)\n",
        "            # shift\n",
        "            shift = np.random.randint(-2, 2, 2)\n",
        "            shift_img = ndimage.shift(rot_img, shift, cval=bg_value)\n",
        "\n",
        "            aug_images.append(shift_img)\n",
        "            aug_labels.append(y)\n",
        "            \n",
        "    # numpy로 변환\n",
        "    aug_images = np.array(aug_images)\n",
        "    aug_labels = np.array(aug_labels)\n",
        "    return aug_images, aug_labels\n",
        "\n",
        "# Mnist 데이터 셋 가져오기\n",
        "mnist = keras.datasets.mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# 이미지들을 255로 나누고 0~1사이로 설정\n",
        "train_images = train_images.astype(np.float32) / 255.\n",
        "test_images = test_images.astype(np.float32) / 255.\n",
        "\n",
        "# train_images 에 4차원구조여야 하는데 채널(4번째꺼)이 없음으로 채워넣음\n",
        "# -1(마지막 차원)에 채널을 하나 추가\n",
        "train_images = np.expand_dims(train_images, axis=-1)\n",
        "test_images = np.expand_dims(test_images, axis=-1)\n",
        "\n",
        "train_labels = to_categorical(train_labels, 10)\n",
        "test_labels = to_categorical(test_labels, 10)\n",
        "\n",
        "# batch 사이즈만큼씩 자르게 설정\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(buffer_size=100000).batch(batch_size)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(batch_size)\n",
        "\n",
        "# 3 네트워크 설정\n",
        "\n",
        "# 모델 생성\n",
        "def create_model():\n",
        "    # Sequential API 사용하겠다고 선언\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Conv2D(filters=32, kernel_size=3, activation=tf.nn.relu, padding='SAME',input_shape=(28, 28, 1)))\n",
        "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
        "    model.add(keras.layers.Conv2D(filters=64, kernel_size=3, activation=tf.nn.relu, padding='SAME'))\n",
        "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
        "    model.add(keras.layers.Conv2D(filters=128, kernel_size=3, activation=tf.nn.relu, padding='SAME'))\n",
        "    model.add(keras.layers.MaxPool2D(padding='SAME'))\n",
        "    # fully connected layer 로 들어가기 전 벡터를 펴주는 단계\n",
        "    model.add(keras.layers.Flatten())\n",
        "    model.add(keras.layers.Dense(256, activation=tf.nn.relu))\n",
        "    # danse layer 의 parameter 가 많아서 dropout 적용\n",
        "    model.add(keras.layers.Dropout(0.4))\n",
        "    model.add(keras.layers.Dense(10))\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "# model.summary()\n",
        "\n",
        "# Loss Function\n",
        "def loss_fn(model, images, labels):\n",
        "    # training = True : dropout 부분에 적용\n",
        "    logits = model(images, training=True)\n",
        "    # Softmax\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
        "            logits=logits, labels=labels))\n",
        "    return loss\n",
        "\n",
        "\n",
        "def grad(model, images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = loss_fn(model, images, labels)\n",
        "        # Backpropagation : 테이프를 거꾸로 감듯이\n",
        "    return tape.gradient(loss, model.variables)\n",
        "\n",
        "# ADAM 옵티마이저 사용\n",
        "optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "def evaluate(model, images, labels):\n",
        "    logits = model(images, training=False)\n",
        "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(cnn=model)\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "    avg_loss = 0.\n",
        "    avg_train_acc = 0.\n",
        "    avg_test_acc = 0.\n",
        "    train_step = 0\n",
        "    test_step = 0\n",
        "\n",
        "    for images, labels in train_dataset:\n",
        "        grads = grad(model, images, labels)\n",
        "        optimizer.apply_gradients(zip(grads, model.variables))\n",
        "        #여기까지만 해도 학습은 완료\n",
        "        loss = loss_fn(model, images, labels)\n",
        "        acc = evaluate(model, images, labels)\n",
        "        avg_loss = avg_loss + loss\n",
        "        # 평균\n",
        "        avg_train_acc = avg_train_acc + acc\n",
        "        train_step += 1\n",
        "    avg_loss = avg_loss / train_step\n",
        "    avg_train_acc = avg_train_acc / train_step\n",
        "\n",
        "    for images, labels in test_dataset:\n",
        "        # 정확도 구현\n",
        "        acc = evaluate(model, images, labels)\n",
        "        avg_test_acc = avg_test_acc + acc\n",
        "        test_step += 1\n",
        "    avg_test_acc = avg_test_acc / test_step\n",
        "\n",
        "    print('Epoch:', '{}'.format(epoch + 1), 'loss =', '{:.8f}'.format(avg_loss),\n",
        "          'train accuracy = ', '{:.4f}'.format(avg_train_acc),\n",
        "          'test accuracy = ', '{:.4f}'.format(avg_test_acc))\n",
        "\n",
        "    checkpoint.save(file_prefix=checkpoint_prefix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Epoch: 1 loss = 0.18518402 train accuracy =  0.9546 test accuracy =  0.9864\n",
            "Epoch: 2 loss = 0.04571076 train accuracy =  0.9897 test accuracy =  0.9895\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ec6e28e717f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m#여기까지만 해도 학습은 완료\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-ec6e28e717f6>\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(model, images, labels)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m# Backpropagation : 테이프를 거꾸로 감듯이\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;31m# ADAM 옵티마이저 사용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    160\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    604\u001b[0m           \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m           data_format=data_format)\n\u001b[0m\u001b[1;32m    607\u001b[0m   ]\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_filter\u001b[0;34m(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[0;34m\"strides\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"explicit_paddings\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m         data_format, \"dilations\", dilations)\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}